@article{gas,
	title={Современные численные методы оптимизации. Метод универсального градиентного спуска},
	author={Гасников, АВ},
	journal={М.: МФТИ},
	year={2018}
}

@inproceedings{agarwal2009information,
	title={Information-theoretic lower bounds on the oracle complexity of convex optimization},
	author={Agarwal, Alekh and Wainwright, Martin J and Bartlett, Peter L and Ravikumar, Pradeep K},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1--9},
	year={2009}
}

@article{duchi2017introductory,
	title={Introductory lectures on stochastic optimization},
	author={Duchi, John C},
	journal={Mathematics of Data},
	volume={16},
	pages={1455},
	year={2017}
}

@article{deng2018optimal,
	title={Optimal Adaptive and Accelerated Stochastic Gradient Descent},
	author={Deng, Qi and Cheng, Yi and Lan, Guanghui},
	journal={arXiv preprint arXiv:1810.00553},
	year={2018}
}

@inproceedings{levy2018online,
	title={Online adaptive methods, universality and acceleration},
	author={Levy, Yehuda Kfir and Yurtsever, Alp and Cevher, Volkan},
	booktitle={Advances in Neural Information Processing Systems},
	pages={6501--6510},
	year={2018}
}

@article{wright2016,
	title={Optimization Algorithms for Data Analysis},
	author={Stephen, J. Wright},
	journal={ IAS/Park City Mathematics
	Series},
	year={2016}
}

@article{gas2016stoch,
	title={Стохастические градиентные методы с неточным оракулом},
	author={Гасников, АВ and Двуреченский, ПЕ and Нестеров, ЮЕ},
	journal={Труды МФТИ},
	volume={8},
	number={1},
	pages={41--91},
	year={2016}
}

@article{ruder2016overview,
	title={An overview of gradient descent optimization algorithms},
	author={Ruder, Sebastian},
	journal={arXiv preprint arXiv:1609.04747},
	year={2016}
}

@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}