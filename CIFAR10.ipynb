{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sverdoot/optimizer-SUG-torch/blob/master/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EToBGXtFYWgd",
        "colab_type": "code",
        "outputId": "cc3ccce5-de01-43af-852a-08bcd8ff0d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wbKsgAwNYVjZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Optimization project\")\n",
        "os.getcwd()\n",
        "import os\n",
        "\n",
        "file_path = \"./CIFAR10\"\n",
        "directory = os.path.dirname(file_path)\n",
        "\n",
        "try:\n",
        "    os.stat(directory)\n",
        "except:\n",
        "    os.mkdir(directory)       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7sdNwaj6hm8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "import math\n",
        "import copy\n",
        "\n",
        "class SUG(Optimizer):\n",
        "    def __init__(self, params, l_0, d_0=0, prob=1., eps=1e-4, momentum=0, dampening=0,\n",
        "                 weight_decay=0, nesterov=False):\n",
        "        if l_0 < 0.0:\n",
        "            raise ValueError(\"Invalid Lipsitz constant of gradient: {}\".format(l_0))\n",
        "        if d_0 < 0.0:\n",
        "            raise ValueError(\"Invalid disperion of gradient: {}\".format(d_0))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        defaults = dict(L=l_0, momentum=momentum, dampening=dampening,\n",
        "                        weight_decay=weight_decay, nesterov=nesterov)\n",
        "        if nesterov and (momentum <= 0 or dampening != 0):\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
        "        self.Lips = l_0\n",
        "        self.prev_Lips = l_0\n",
        "        self.D_0 = d_0\n",
        "        self.eps = eps\n",
        "        self.prob = prob\n",
        "        self.start_param = params\n",
        "        self.upd_sq_grad_norm = None\n",
        "        self.sq_grad_norm = None\n",
        "        self.loss = torch.tensor(0.)\n",
        "        self.closure = None\n",
        "        super(SUG, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(SUG, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    def comp_batch_size(self):\n",
        "        \"\"\"Returns optimal batch size for given d_0, eps and l_0;\n",
        "\n",
        "        \"\"\"\n",
        "        return math.ceil(2 * self.D_0 * self.eps / self.prev_Lips)\n",
        "\n",
        "    def step(self, loss, closure):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            loss : current loss\n",
        "\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        self.start_params = []\n",
        "        self.loss = loss\n",
        "        self.sq_grad_norm = 0\n",
        "        self.closure = closure\n",
        "        for gr_idx, group in enumerate(self.param_groups):\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            dampening = group['dampening']\n",
        "            nesterov = group['nesterov']\n",
        "            self.start_params.append([])\n",
        "            for p_idx, p in enumerate(group['params']):\n",
        "                self.start_params[gr_idx].append([p.data])\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                self.start_params[gr_idx][p_idx].append(p.grad.data)\n",
        "                d_p = self.start_params[gr_idx][p_idx][1]\n",
        "                p_ = self.start_params[gr_idx][p_idx][0]\n",
        "                self.sq_grad_norm += torch.sum(p.grad.data * p.grad.data)\n",
        "                \n",
        "                if weight_decay != 0:\n",
        "                   d_p.add_(weight_decay, p.data)\n",
        "                \n",
        "                if momentum != 0:\n",
        "                    param_state = self.state[p]\n",
        "                    if 'momentum_buffer' not in param_state:\n",
        "                        buf = param_state['momentum_buffer'] = torch.zeros_like(p.data)\n",
        "                        buf.mul_(momentum).add_(d_p)\n",
        "                    else:\n",
        "                        buf = param_state['momentum_buffer']\n",
        "                        buf.mul_(momentum).add_(1 - dampening, d_p)\n",
        "                    if nesterov:\n",
        "                        d_p = d_p.add(momentum, buf)\n",
        "                    else:\n",
        "                        d_p = buf\n",
        "                self.start_params[gr_idx][p_idx][1] = d_p\n",
        "        i = 0\n",
        "        difference = -1\n",
        "        while difference < 0:\n",
        "            self.Lips = max(self.prev_Lips * 2 ** (i - 1), 2.)\n",
        "            for gr_idx, group in enumerate(self.param_groups):\n",
        "                for p_idx, p in enumerate(group['params']):\n",
        "                    if p.grad is None:\n",
        "                        continue\n",
        "                    start_param_val = self.start_params[gr_idx][p_idx][0]\n",
        "                    start_param_grad = self.start_params[gr_idx][p_idx][1]\n",
        "                    p.data = start_param_val - 1/(2*self.Lips) * start_param_grad\n",
        "            difference, upd_loss = self.stop_criteria()\n",
        "            i += 1\n",
        "        self.prev_Lips = self.Lips\n",
        "\n",
        "        return self.Lips, i\n",
        "\n",
        "    def stop_criteria(self):\n",
        "        \"\"\"Checks if the Lipsitz constant of gradient is appropriate\n",
        "        \n",
        "           <g(x_k), w_k - x_k> + 2L_k / 2 ||x_k - w_k||^2 = - 1 / (2L_k)||g(x_k)||^2 + 1 / (4L_k)||g(x_k)||^2 = -1 / (4L_k)||g(x_k)||^2                \n",
        "        \"\"\"\n",
        "        cur_loss = self.loss.item()\n",
        "        upd_loss = self.closure().item()\n",
        "        major =  cur_loss - 1 / (4 * self.Lips) * self.sq_grad_norm\n",
        "        return major - upd_loss + self.eps / 10, upd_loss\n",
        "\n",
        "    def get_lipsitz_const(self):\n",
        "        \"\"\"Returns current Lipsitz constant of the gradient of the loss function\n",
        "        \"\"\"\n",
        "        return self.Lips\n",
        "    \n",
        "    def get_sq_grad(self):\n",
        "        \"\"\"Returns the current second norm of the gradient of the loss function \n",
        "           calculated by the formula\n",
        "           \n",
        "           ||f'(p_1,...,p_n)||_2^2 ~ \\sum\\limits_{i=1}^n ((df/dp_i)(p1,...,p_n))^2 \n",
        "        \"\"\"\n",
        "        self.upd_sq_grad_norm = 0\n",
        "        for gr_idx, group in enumerate(self.param_groups):\n",
        "            for p_idx, p in enumerate(group['params']):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                self.upd_sq_grad_norm += torch.sum(p.grad.data * p.grad.data) \n",
        "        \n",
        "        return self.upd_sq_grad_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yjtZDmg7YmpZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7txImi-VYhOM",
        "colab_type": "code",
        "outputId": "8b8dbd23-d2a9-4526-9df7-1f9b6495d0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "mBA2Gv8ZqT1T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "sS_wSA0-qV0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-LK93IAGkTlD",
        "colab_type": "code",
        "outputId": "e61107d8-4cf1-4937-eef6-c7469637e11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "valid_dataset = torchvision.datasets.CIFAR10(root='/data', train=True, \n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PEl5iQJ9ZZ4n",
        "colab_type": "code",
        "outputId": "50e2557b-4288-4e51-85d7-15e34cea3f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "valid_size=0.15\n",
        "num_train = len(trainset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "               batch_size=batch_size, sampler=train_sampler,\n",
        "               num_workers=2)\n",
        "\n",
        "validloader = torch.utils.data.DataLoader(valid_dataset, \n",
        "               batch_size=batch_size, sampler=valid_sampler,\n",
        "               num_workers=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/170498071 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:47, 4113251.36it/s]                               "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4yhxBsWJGdsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchs_per_epoch = len(trainloader) / batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LCF6wqjvqQf2",
        "colab_type": "code",
        "outputId": "dcc96fd8-206f-452a-9c88-29ea57da6b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(validloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print('\\t'.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "truck\t deer\thorse\t ship\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-VAUL8ZkoKPw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "o-Su2BI5Zw_c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### simple CNN"
      ]
    },
    {
      "metadata": {
        "id": "oNiBcg-QkYzu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFUdCfE9oOwh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train"
      ]
    },
    {
      "metadata": {
        "id": "P31TyRm2tcgN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def model_step(model, optimizer, criterion, inputs, labels):\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    if model.training:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "    if optimizer.__class__.__name__ != 'SUG':\n",
        "        optimizer.step()\n",
        "    else:\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            upd_outputs = model(inputs)\n",
        "            upd_loss = criterion(upd_outputs, labels)\n",
        "            upd_loss.backward()\n",
        "            return upd_loss\n",
        "\n",
        "        optimizer.step(loss, closure)\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ECO6k5-xkzl1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, criterion, optimizer, n_epochs=2, validloader=None, eps=1e-5, print_every=1):\n",
        "    tr_loss, val_loss, lips, times, grad, acc = ([] for i in range(6))\n",
        "    start_time = time.time()\n",
        "    model.to(device=device)\n",
        "    for ep in range(n_epochs):\n",
        "        model.train()\n",
        "        i = 0\n",
        "        for i, data in enumerate(trainloader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = Variable(inputs).to(device=device), Variable(labels).to(device=device)\n",
        "\n",
        "            tr_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
        "            if optimizer.__class__.__name__ == 'SUG':\n",
        "                lips.append(optimizer.get_lipsitz_const())\n",
        "                grad.append(optimizer.get_sq_grad)\n",
        "        times.append(time_since(start_time))\n",
        "        if ep % print_every == 0:\n",
        "            print(\"Epoch {}, training loss {}, time passed {}\".format(ep, sum(tr_loss[-i:]) / i, time_since(start_time)))\n",
        "\n",
        "        if validloader is None:\n",
        "            continue\n",
        "        model.zero_grad()\n",
        "        model.eval()\n",
        "        j = 0\n",
        "        for j, data in enumerate(validloader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
        "            val_loss.append(model_step(model, optimizer, criterion, inputs, labels))\n",
        "        if ep % print_every == 0:\n",
        "            print(\"Validation loss {}\".format(sum(val_loss[-j:]) / j))\n",
        "        \n",
        "    return tr_loss, times, val_loss, lips, grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wX-aY0Qmi3NP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concat_states(state1, state2):\n",
        "    states = {\n",
        "            'epoch': state1['epoch'] + state2['epoch'],\n",
        "            'state_dict': state2['state_dict'],\n",
        "            'optimizer': state2['optimizer'],\n",
        "            'tr_loss' : state1['tr_loss'] + state2['tr_loss'],\n",
        "            'val_loss' : state1['val_loss'] + state2['val_loss'],\n",
        "            'lips' : state1['lips'] + state2['lips'],\n",
        "            'grad' : state1['grad'] + state2['grad'],\n",
        "            'times' : state1['times'] + list(map(lambda x: x + state1['times'][-1],state2['times']))\n",
        "             }\n",
        "    return states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZrx1G-ykasC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_every = 4\n",
        "n_epochs = 20\n",
        "tr_loss = {}\n",
        "tr_loss['sgd'] = {}\n",
        "val_loss = {}\n",
        "val_loss['sgd'] = {}\n",
        "lrs = [0.01, 0.005]\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63LQotmbkdOx",
        "colab_type": "code",
        "outputId": "a69af6bd-bdc8-47af-9a06-a0975b64d919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "for lr in lrs:\n",
        "  model = CNN()\n",
        "  #state = torch.load('./CIFAR10/CNN_' + str(lr))\n",
        "  #model.load_state_dict(state['state_dict'])\n",
        "  #model.load_state_dict(state)\n",
        "  print(\"SGD  lr={}, momentum=0. :\".format(lr))\n",
        "  #model = CNN()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n",
        "  tr_loss['sgd'][lr], times, val_loss['sgd'][lr], lips, grad = train(model, trainloader, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=validloader)\n",
        "  states = {\n",
        "            'epoch': n_epochs,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'tr_loss' : tr_loss['sgd'][lr],\n",
        "            'val_loss' : val_loss['sgd'][lr],\n",
        "            'lips' : lips,\n",
        "            'grad' : grad,\n",
        "            'times' : times\n",
        "             }\n",
        "  #state = concat_states(state, states)\n",
        "  torch.save(states, './CIFAR10/CNN_' + str(lr))\n",
        "  #torch.save(states, './CIFAR10/CNN_' + str(lr))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD  lr=0.01, momentum=0. :\n",
            "Epoch 0, training loss 0.6779449275605022, time passed 0m 37s\n",
            "Validation loss 0.6575411162483272\n",
            "Epoch 4, training loss 0.6189495169961579, time passed 3m 33s\n",
            "Validation loss 0.9533135285690475\n",
            "Epoch 8, training loss 0.6028648142686046, time passed 6m 27s\n",
            "Validation loss 1.1153351957477398\n",
            "SGD  lr=0.005, momentum=0. :\n",
            "Epoch 0, training loss 0.5732823346393654, time passed 0m 42s\n",
            "Validation loss 0.5828254481612555\n",
            "Epoch 4, training loss 0.48028830949116097, time passed 3m 39s\n",
            "Validation loss 0.8323193062554047\n",
            "Epoch 8, training loss 0.4310017076898815, time passed 6m 36s\n",
            "Validation loss 0.9820830017614517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hvlraX6DkqTF",
        "colab_type": "code",
        "outputId": "32aed9be-d324-456b-ae87-108800ecb72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "l_0 = 2\n",
        "model = CNN()\n",
        "#n_epochs = 4\n",
        "optimizer = SUG(model.parameters(), l_0=l_0, momentum=0.)\n",
        "tr_loss['sug'], times, val_loss['sug'], lips, grad = train(model, trainloader, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=validloader)\n",
        "states = {\n",
        "            'epoch': n_epochs,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'tr_loss' : tr_loss['sug'],\n",
        "            'val_loss' : val_loss['sug'],\n",
        "            'lips' : lips,\n",
        "            'grad' : grad,\n",
        "            'times' : times\n",
        "        }\n",
        "torch.save(states, './CIFAR10/CNN_sug')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, training loss 0.4989453318882285, time passed 1m 29s\n",
            "Validation loss 0.49379758652907935\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}