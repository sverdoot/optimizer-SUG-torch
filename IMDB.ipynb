{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sverdoot/optimizer-SUG-torch/blob/master/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZFVJjSCXnAz_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext import data, datasets\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "# set up fields\n",
        "TEXT = data.Field(lower=True, include_lengths=True, batch_first=True, pad_token='<PAD_TOKEN>', eos_token='<EOS_TOKEN>', unk_token='<UNK_TOKEN>')\n",
        "LABEL = data.Field(sequential=False)\n",
        "\n",
        "# make splits for data\n",
        "train_, test_ = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "# build the vocabulary\n",
        "TEXT.build_vocab(train_, vectors=GloVe(name='6B', dim=300))\n",
        "LABEL.build_vocab(train_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYZ2YZPO3RoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3c4a06a-c272-452a-e84c-2e96783a97b3"
      },
      "cell_type": "code",
      "source": [
        "len(train_), len(test_)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1148, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "tgyilCWWp1ml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "# make iterator for splits\n",
        "train_iter, val_iter = data.BucketIterator.splits(\n",
        "    (train_, test_), batch_size=4, device=device, sort_within_batch=True, sort_key=lambda x: len(x.text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlidBWmDqA7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "61pzzXOlTnA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/Optimization project\")\n",
        "os.getcwd()\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/Optimization project/IMDB\"\n",
        "#directory = os.path.dirname(file_path)\n",
        "\n",
        "try:\n",
        "    os.stat(file_path)\n",
        "except:\n",
        "os.mkdir(file_path)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mj8HZFVVUilO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sug\n",
        "from sug import SUG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "envfb4TdNSY2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ]
    },
    {
      "metadata": {
        "id": "SJrq8RrAYS7F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a, b = next(iter(train_iter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2I0nvFqYjqW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(inputs, lens), labels = a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Am3aEm7ZPgB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs.size(), lens.size(), labels.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHQxrPhc9g4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "D-WcYYATWwA3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        " \n",
        "class SimpleLSTMBaseline(nn.Module):\n",
        "    def __init__(self, hidden_dim, emb_dim=300, num_linear=1):\n",
        "        super().__init__() \n",
        "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
        "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=2, bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.linear1 = nn.Linear(2 * hidden_dim, 20)\n",
        "        self.linear1.weight.data.fill_(0.01)\n",
        "        self.linear2 = nn.Linear(20, 2)\n",
        "        self.linear2.weight.data.fill_(0.01)\n",
        " \n",
        "    def forward(self, seq, lens):\n",
        "        embeds = self.embedding(seq)\n",
        "        packed = pack_padded_sequence(embeds, lens, batch_first=True)\n",
        "        hdn, _ = self.encoder(packed)\n",
        "        hdn, _ = pad_packed_sequence(hdn, batch_first=True)\n",
        "        output = nn.functional.max_pool1d(hdn, kernel_size=10)\n",
        "        output = F.relu(self.linear1(hdn[:,1,:]))\n",
        "        prob = F.log_softmax(self.linear2(output), -1)\n",
        "        \n",
        "        return prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3VbVMHjn9jlN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "QcDvlJrWh_0X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def model_step(model, optimizer, criterion, inputs, lens, labels):\n",
        "    outputs = model(inputs, lens)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    if model.training:\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)\n",
        "    if optimizer.__class__.__name__ != 'SUG':\n",
        "        optimizer.step()\n",
        "    else:\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            upd_outputs = model(inputs, lens)\n",
        "            upd_loss = criterion(upd_outputs, labels)\n",
        "            upd_loss.backward()\n",
        "            return upd_loss\n",
        "\n",
        "        optimizer.step(loss, closure)\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KXe4_d-Ziami",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, criterion, optimizer, path=None, n_epochs=2, validloader=None, eps=1e-5, print_every=1):\n",
        "    tr_loss, val_loss, lips, times, grad, acc = ([] for i in range(6))\n",
        "    start_time = time.time()\n",
        "    model.to(device=device)\n",
        "    print(len(list(trainloader)))\n",
        "    for ep in range(n_epochs):\n",
        "        model.train()\n",
        "        i = 0\n",
        "        for i, (data, b) in enumerate(trainloader):\n",
        "            (inputs, lens), labels = data\n",
        "            inputs, labels = Variable(inputs).to(device=device), Variable(labels).to(device=device)\n",
        "\n",
        "            tr_loss.append(model_step(model, optimizer, criterion, inputs, lens, labels))      \n",
        "                \n",
        "            if optimizer.__class__.__name__ == 'SUG':\n",
        "                lips.append(optimizer.get_lipsitz_const())\n",
        "                grad.append(optimizer.get_sq_grad)\n",
        "            if i % 10 == 0:\n",
        "                print(tr_loss[-1], i)\n",
        "                times.append(time_since(start_time))\n",
        "                model.zero_grad()\n",
        "                optimizer.zero_grad()\n",
        "                states = {\n",
        "                         'epoch': n_epochs,\n",
        "                         'state_dict': model.state_dict(),\n",
        "                         'optimizer': optimizer.state_dict(),\n",
        "                         'tr_loss' : tr_loss,\n",
        "                         'val_loss' : val_loss,\n",
        "                         'lips' : lips,\n",
        "                         'grad' : grad,\n",
        "                         'times' : times\n",
        "                         }     \n",
        "                if path is not None:\n",
        "                    torch.save(states, path)\n",
        "        \n",
        "        times.append(time_since(start_time))\n",
        "        if ep % print_every == 0:\n",
        "            print(\"Epoch {}, training loss {}, time passed {}\".format(ep, sum(tr_loss[-i:]) / i, time_since(start_time)))\n",
        "\n",
        "        #if validloader is None:\n",
        "        #    continue\n",
        "        #model.zero_grad()\n",
        "        #model.eval()\n",
        "        #j = 0\n",
        "        #for j, (data, b) in enumerate(validloader):\n",
        "        #    (inputs, lens), labels = data\n",
        "        #    inputs, labels = inputs.to(device=device), labels.to(device=device)\n",
        "        #    val_loss.append(model_step(model, optimizer, criterion, inputs, lens, labels))\n",
        "        #if ep % print_every == 0:\n",
        "        #    print(\"Validation loss {}\".format(sum(val_loss[-j:]) / j))\n",
        "        #\n",
        "    return tr_loss, times, val_loss, lips, grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mvhnRhO8ifa4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concat_states(state1, state2):\n",
        "    states = {\n",
        "            'epoch': state1['epoch'] + state2['epoch'],\n",
        "            'state_dict': state2['state_dict'],\n",
        "            'optimizer': state2['optimizer'],\n",
        "            'tr_loss' : state1['tr_loss'] + state2['tr_loss'],\n",
        "            'val_loss' : state1['val_loss'] + state2['val_loss'],\n",
        "            'lips' : state1['lips'] + state2['lips'],\n",
        "            'grad' : state1['grad'] + state2['grad'],\n",
        "            #'times' : state1['times'] + list(map(lambda x: x + state1['times'][-1],state2['times']))\n",
        "             'times' : state1['times'] + state2['times']\n",
        "             }\n",
        "    return states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHhBIzadidIY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_every = 1\n",
        "n_epochs = 1\n",
        "tr_loss = {}\n",
        "tr_loss['sgd'] = {}\n",
        "val_loss = {}\n",
        "val_loss['sgd'] = {}\n",
        "lrs = [0.01, 0.005]\n",
        "em_sz = 100\n",
        "nh = 500\n",
        "nl = 3\n",
        "torch.manual_seed(999)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g54jro1O2vsA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ada01a2-0a6d-4558-a4fa-ff8f16102e11"
      },
      "cell_type": "code",
      "source": [
        "len(list(train_iter))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "metadata": {
        "id": "7UlvhRuDQ-Tg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_iter_ = val_iter[:len(list(train_iter))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhytd4Y-iiKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for lr in lrs:\n",
        "  model = SimpleLSTMBaseline(nh, emb_dim=em_sz)\n",
        "  print(\"SGD  lr={}, momentum=0. :\".format(lr))\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n",
        "  tr_loss['sgd'][lr], times, val_loss['sgd'][lr], lips, grad = train(model, train_iter, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=val_iter)\n",
        "  states = {\n",
        "            'epoch': n_epochs,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'tr_loss' : tr_loss['sgd'][lr],\n",
        "            'val_loss' : val_loss['sgd'][lr],\n",
        "            'lips' : lips,\n",
        "            'grad' : grad,\n",
        "            'times' : times\n",
        "             }\n",
        "  torch.save(states, './IMDB/LSTM_' + str(lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdwWe20ikVEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "e6cdec79-8e00-49dd-cf41-513a2e96c241"
      },
      "cell_type": "code",
      "source": [
        "l_0 = 2\n",
        "model = SimpleLSTMBaseline(nh, emb_dim=em_sz)\n",
        "print(\"SUG  l_0={}, momentum=0. :\".format(l_0))\n",
        "optimizer = SUG(model.parameters(), l_0=l_0, momentum=0.)\n",
        "tr_loss['sgd'][lr], times, val_loss['sgd'][lr], lips, grad = train(model, train_iter, criterion, optimizer, path='./IMDB/LSTM_sug', n_epochs=n_epochs, print_every=print_every, validloader=val_iter)\n",
        "states = {\n",
        "          'epoch': n_epochs,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "          'tr_loss' : tr_loss['sgd'][lr],\n",
        "          'val_loss' : val_loss['sgd'][lr],\n",
        "          'lips' : lips,\n",
        "          'grad' : grad,\n",
        "          'times' : times\n",
        "           }\n",
        "torch.save(states, './IMDB/LSTM_sug')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUG  l_0=2, momentum=0. :\n",
            "287\n",
            "0.7064298391342163 0\n",
            "0.10949906706809998 10\n",
            "0.03670758008956909 20\n",
            "0.019243312999606133 30\n",
            "0.010921110399067402 40\n",
            "0.007866695523262024 50\n",
            "0.005721421912312508 60\n",
            "0.005002093501389027 70\n",
            "0.0037729735486209393 80\n",
            "0.0030055076349526644 90\n",
            "0.0026158031541854143 100\n",
            "0.0025622034445405006 110\n",
            "0.00234255101531744 120\n",
            "0.0017376202158629894 130\n",
            "0.001502203056588769 140\n",
            "0.0014089700998738408 150\n",
            "0.001433861325494945 160\n",
            "0.001311229425482452 170\n",
            "0.0011016679927706718 180\n",
            "0.00109789427369833 190\n",
            "0.0009428689954802394 200\n",
            "0.0008233338594436646 210\n",
            "0.0009007734479382634 220\n",
            "0.0007441784837283194 230\n",
            "0.0006538216257467866 240\n",
            "0.0006377806421369314 250\n",
            "0.0005877303192391992 260\n",
            "0.0006665069377049804 270\n",
            "0.0005683102062903345 280\n",
            "Epoch 0, training loss 0.014863820818384745, time passed 143m 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7feq4xNv4eRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "d600e9e0-c57d-492d-d5e5-753ba5df3376"
      },
      "cell_type": "code",
      "source": [
        "lr = 0.05\n",
        "model = SimpleLSTMBaseline(nh, emb_dim=em_sz)\n",
        "print(\"SGD  lr={}, momentum=0. :\".format(lr))\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.)\n",
        "tr_loss['sgd'][lr], times, val_loss['sgd'][lr], lips, grad = train(model, train_iter, criterion, optimizer, n_epochs=n_epochs, print_every=print_every, validloader=val_iter)\n",
        "states = {\n",
        "            'epoch': n_epochs,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'tr_loss' : tr_loss['sgd'][lr],\n",
        "            'val_loss' : val_loss['sgd'][lr],\n",
        "            'lips' : lips,\n",
        "            'grad' : grad,\n",
        "            'times' : times\n",
        "             }\n",
        "torch.save(states, './IMDB/LSTM_' + str(lr))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD  lr=0.05, momentum=0. :\n",
            "287\n",
            "0.5988515615463257 0\n",
            "0.41938233375549316 10\n",
            "0.3074619472026825 20\n",
            "0.23368413746356964 30\n",
            "0.18257474899291992 40\n",
            "0.14501415193080902 50\n",
            "0.11993587017059326 60\n",
            "0.09823356568813324 70\n",
            "0.08181726187467575 80\n",
            "0.06902245432138443 90\n",
            "0.05924888700246811 100\n",
            "0.05311816185712814 110\n",
            "0.04379794001579285 120\n",
            "0.03996816277503967 130\n",
            "0.03634902834892273 140\n",
            "0.030864223837852478 150\n",
            "0.027338199317455292 160\n",
            "0.024336742237210274 170\n",
            "0.022301625460386276 180\n",
            "0.021165722981095314 190\n",
            "0.019693579524755478 200\n",
            "0.018488040193915367 210\n",
            "0.016197815537452698 220\n",
            "0.01575876586139202 230\n",
            "0.013274822384119034 240\n",
            "0.013141696341335773 250\n",
            "0.012804633937776089 260\n",
            "0.011515684425830841 270\n",
            "0.011610937304794788 280\n",
            "Epoch 0, training loss 0.08387096615026256, time passed 71m 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4WmDxq7dDHdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}